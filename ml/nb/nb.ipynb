{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Theory Overview\n",
    "\n",
    "The Naive Bayes is classification algorithm that exploits the product rule in probability theory. The probability of an unknown data sample $k$ belonging to class $C$ is given by:\n",
    "\n",
    "$P(C_{k}|\\textbf{x}) = \\frac{P(C_{k})P(\\textbf{x}|C_{k})}{P(\\textbf{x})}$\n",
    "\n",
    "In practice, it is extremely difficult to calculate the probability in the denominator. Luckily, it is the same for all classes and thus can be regarded as a constant which can be omitted. So we only need to pay attention to the numerator. Assume that there are $N$ samples, $k$ of which belong to class $C$, then it is easy to derive the prior probability:\n",
    "\n",
    "$P(C_{k}) = \\frac{k}{N}$\n",
    "\n",
    "In order to compute the posterior probability, we assume the samples are retrieved from Gaussian distribution whose mean and covariance are the mean and covariance of the whole training dataset. Thus, the posterior probability can be computed as:\n",
    "\n",
    "$P(\\textbf{x}|C_{k}) = \\textit{N}(\\mu, \\sigma^{2})$\n",
    "\n",
    "In order to avoid numerical underflow, it is typical to take the logarithmic form of the probability(note that logarithmic function is monotonic), so the final formula becomes:\n",
    "\n",
    "$log(P(C_{k}|\\textbf{x})) = log(P(C_{k})) + log(P(x_{1}|C_{k})) + log(P(x_{2}|C_{k})) + ... + log(P(x_{d}|C_{k}))$\n",
    "\n",
    "where $d$ is the dimension of the feature vector. Note that here we assume all features are independent of each other, which is a strong(\"naive\") assumption and usually not true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Naive Bayes for Binary Classification\n",
    "\n",
    "In this example, we will use NB to classify whether a patient has diabetes or not. The model is evaluated using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the 1th validation, the accuracy is 75.32%\n",
      "For the 2th validation, the accuracy is 77.27%\n",
      "For the 3th validation, the accuracy is 72.73%\n",
      "For the 4th validation, the accuracy is 77.27%\n",
      "For the 5th validation, the accuracy is 78.57%\n",
      "For the 6th validation, the accuracy is 72.73%\n",
      "For the 7th validation, the accuracy is 77.27%\n",
      "For the 8th validation, the accuracy is 70.78%\n",
      "For the 9th validation, the accuracy is 72.73%\n",
      "For the 10th validation, the accuracy is 72.73%\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('pima-indians-diabetes.csv', header = None).values\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "split = int(0.8*data.shape[0]) # randomly split the data set into 80% training and 20% testing\n",
    "\n",
    "# perform cross validation 10 times\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    rand_idx = np.arange(data.shape[0])\n",
    "    np.random.shuffle(rand_idx) \n",
    "    train_data = data[rand_idx[0:split]]\n",
    "    test_data = data[rand_idx[split:]]\n",
    "    \n",
    "    # data is either labeled as \"1\"(positive) or \"0\"(negative)\n",
    "    train_pos = train_data[np.where(train_data.T[-1] == 1)]\n",
    "    train_neg = train_data[np.where(train_data.T[-1] == 0)]\n",
    "    test_pos = test_data[np.where(test_data.T[-1] == 1)]\n",
    "    test_neg = test_data[np.where(test_data.T[-1] == 0)]\n",
    "    \n",
    "    # calculate mean and covariance of positive and negative data samples, respectively\n",
    "    pos_mean = np.nanmean(train_pos, axis=0)\n",
    "    pos_var = np.nanvar(train_pos, axis=0)\n",
    "    neg_mean = np.nanmean(train_neg, axis=0)\n",
    "    neg_var = np.nanvar(train_neg, axis=0)\n",
    "    \n",
    "    err = 0\n",
    "    \n",
    "    # calculate prior logarithmic probability\n",
    "    pos_prior_prob = log(test_pos.shape[0]/test_data.shape[0])\n",
    "    neg_prior_prob = log(test_neg.shape[0]/test_data.shape[0])\n",
    "    \n",
    "    for row in test_data:         \n",
    "        \n",
    "        # compute and compare the probability of both cases to predict label of test data\n",
    "        pos_prob = pos_prior_prob + log(multivariate_normal.pdf(row[0:-1], pos_mean[0:-1], pos_var[0:-1]))\n",
    "        neg_prob = neg_prior_prob + log(multivariate_normal.pdf(row[0:-1], neg_mean[0:-1], neg_var[0:-1]))\n",
    "\n",
    "        if pos_prob >= neg_prob:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "    \n",
    "        if label != row[-1]:\n",
    "            err += 1\n",
    "            \n",
    "    acc = 1 - err/test_data.shape[0]\n",
    "    print('For the {}th validation, the accuracy is {:.2f}%'.format(i+1, acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
